import cv2
import numpy as np
import os
from collections import deque

# åƒæ•¸è¨­å®š
# Parameter Configuration
# âœ… èª¿æ•´æ­¤è™•çš„ maxlen æ•¸å€¼ä»¥æ§åˆ¶åæ‡‰é€Ÿåº¦ã€‚æ•¸å€¼è¶Šå°ï¼Œåæ‡‰è¶Šå¿«ï¼Œä½†å¯èƒ½æŠ–å‹•æœƒå¢åŠ ã€‚
# ä½‡åˆ—ç¾åœ¨å„²å­˜çš„æ˜¯å¤šé …å¼ä¿‚æ•¸
left_history = deque(maxlen=5) 
right_history = deque(maxlen=5)

# åƒæ•¸åŒ– Bird's Eye View çš„ä¾†æºé»ï¼Œæ–¹ä¾¿æ‰‹å‹•èª¿æ ¡
# These points are relative to the image dimensions (width, height).
# These are the corners of the trapezoid ROI in the original image.
BEV_SRC_POINTS_REL = np.float32([
    [0.25, 0.95],
    [0.75, 0.95],
    [0.6, 0.55],
    [0.4, 0.55]
])

# æ–°å¢åƒæ•¸ï¼šè£åˆ‡æ‰ç•«é¢çš„åº•éƒ¨ç™¾åˆ†æ¯”
# New parameter: Percentage of the bottom of the frame to crop
CROP_BOTTOM_PERCENTAGE = 0.3

# ğŸ” 1. å¤šå±¤æ¬¡çš„è»Šé“ç·šåµæ¸¬ç­–ç•¥
def preprocess_frame(frame):
    """
    çµåˆé¡è‰²èˆ‡æ¢¯åº¦äºŒå€¼åŒ–ï¼Œå¢å¼·åœ¨ä¸åŒå…‰ç·šæ¢ä»¶ä¸‹çš„ç©©å¥æ€§ã€‚
    Returns a combined binary image.
    """
    # âœ… é¡è‰²èˆ‡æ¢¯åº¦äºŒå€¼åŒ–çµåˆ
    # HLS è‰²å½©ç©ºé–“ç”¨æ–¼åµæ¸¬ç™½è‰²èˆ‡é»ƒè‰²ç·šæ¢ï¼Œå°å…‰ç·šè®ŠåŒ–æ›´ä¸æ•æ„Ÿ
    hls = cv2.cvtColor(frame, cv2.COLOR_BGR2HLS)
    white_mask = cv2.inRange(hls, np.array([0, 200, 0]), np.array([255, 255, 255]))
    yellow_mask = cv2.inRange(hls, np.array([15, 30, 115]), np.array([35, 204, 255]))
    color_mask = cv2.bitwise_or(white_mask, yellow_mask)

    # Sobel æ¢¯åº¦åµæ¸¬ï¼Œç”¨æ–¼æ‰¾å‡ºæ‰€æœ‰é«˜å°æ¯”åº¦çš„é‚Šç·£
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)
    abs_sobelx = np.absolute(sobelx)
    sobel_mask = cv2.inRange(np.uint8(255 * abs_sobelx / np.max(abs_sobelx)), 50, 255)

    # çµåˆå…©ç¨®é®ç½©
    combined_mask = cv2.bitwise_or(color_mask, sobel_mask)
    return combined_mask

# âœ… é³¥ç°è¦–è§’è½‰æ›ï¼ˆBirdâ€™s Eye Viewï¼‰
def get_perspective_transforms(frame):
    """
    å°‡ç•«é¢è½‰æ›ç‚ºä¿¯è¦–è¦–è§’ï¼Œå°‡æ›²ç·šè½‰ç‚ºæ¥è¿‘ç›´ç·šï¼Œä¾¿æ–¼å¾ŒçºŒè»Šé“ç·šæª¢æ¸¬èˆ‡æ“¬åˆã€‚
    å–å¾— Birdâ€™s Eye View (é€è¦–è½‰æ›) çš„è½‰æ›çŸ©é™£ã€‚
    è¼¸å…¥: BGR æˆ–ç°éš frame
    è¼¸å‡º: æ­£å‘å’Œåå‘çš„è½‰æ›çŸ©é™£ M å’Œ Minv
    """
    height, width = frame.shape[:2]

    # Use the global parameter to define the source points
    src = np.float32([
        [width * BEV_SRC_POINTS_REL[0, 0], height * BEV_SRC_POINTS_REL[0, 1]],
        [width * BEV_SRC_POINTS_REL[1, 0], height * BEV_SRC_POINTS_REL[1, 1]],
        [width * BEV_SRC_POINTS_REL[2, 0], height * BEV_SRC_POINTS_REL[2, 1]],
        [width * BEV_SRC_POINTS_REL[3, 0], height * BEV_SRC_POINTS_REL[3, 1]]
    ])
    
    # è¨ˆç®—ç›®æ¨™é»
    # Define the new dst points as a perfect rectangle,
    # mapping the src trapezoid to the entire output frame.
    dst = np.float32([
        [0, height],        # bottom-left
        [width, height],    # bottom-right
        [width, 0],         # top-right
        [0, 0]              # top-left
    ])

    M = cv2.getPerspectiveTransform(src, dst)
    Minv = cv2.getPerspectiveTransform(dst, src)
    return M, Minv

# ğŸ§  2. æ™ºèƒ½åŒ–è»Šé“ç·šæ“¬åˆæµç¨‹ - æ»‘å‹•è¦–çª—æ¼”ç®—æ³•
def find_lane_pixels_and_fit_poly(binary_warped):
    """
    ä½¿ç”¨æ»‘å‹•è¦–çª—æ¼”ç®—æ³•åœ¨äºŒå€¼åŒ–é³¥ç°åœ–ä¸Šå°‹æ‰¾è»Šé“ç·šåƒç´ ï¼Œä¸¦æ“¬åˆå¤šé …å¼æ›²ç·šã€‚
    """
    # è¨ˆç®—ç›´æ–¹åœ–ä»¥æ‰¾åˆ°è»Šé“ç·šçš„åº•éƒ¨èµ·é»
    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)
    
    midpoint = np.int32(histogram.shape[0]//2)
    leftx_base = np.argmax(histogram[:midpoint])
    rightx_base = np.argmax(histogram[midpoint:]) + midpoint

    # æ»‘å‹•è¦–çª—è¨­å®š
    nwindows = 9
    window_height = np.int32(binary_warped.shape[0]//nwindows)
    nonzero = binary_warped.nonzero()
    nonzeroy = np.array(nonzero[0])
    nonzerox = np.array(nonzero[1])
    
    leftx_current = leftx_base
    rightx_current = rightx_base
    
    margin = 100
    minpix = 50
    
    left_lane_inds = []
    right_lane_inds = []

    # éæ­·æ‰€æœ‰æ»‘å‹•è¦–çª—
    for window in range(nwindows):
        win_y_low = binary_warped.shape[0] - (window+1)*window_height
        win_y_high = binary_warped.shape[0] - window*window_height
        win_x_low_l = leftx_current - margin
        win_x_high_l = leftx_current + margin
        win_x_low_r = rightx_current - margin
        win_x_high_r = rightx_current + margin
        
        # è­˜åˆ¥è¦–çª—å…§çš„éé›¶åƒç´ 
        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & 
                          (nonzerox >= win_x_low_l) & (nonzerox < win_x_high_l)).nonzero()[0]
        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & 
                           (nonzerox >= win_x_low_r) & (nonzerox < win_x_high_r)).nonzero()[0]
        
        left_lane_inds.append(good_left_inds)
        right_lane_inds.append(good_right_inds)
        
        # å¦‚æœæ‰¾åˆ°è¶³å¤ å¤šçš„åƒç´ ï¼Œæ›´æ–°ä¸‹ä¸€å€‹è¦–çª—çš„ä¸­å¿ƒä½ç½®
        if len(good_left_inds) > minpix:
            leftx_current = np.int32(np.mean(nonzerox[good_left_inds]))
        if len(good_right_inds) > minpix:        
            rightx_current = np.int32(np.mean(nonzerox[good_right_inds]))

    # å°‡æ‰€æœ‰åƒç´ ç´¢å¼•ä¸²é€£èµ·ä¾†
    try:
        left_lane_inds = np.concatenate(left_lane_inds)
        right_lane_inds = np.concatenate(right_lane_inds)
    except ValueError:
        pass
    
    # æå–è»Šé“ç·šåƒç´ çš„åº§æ¨™
    leftx = nonzerox[left_lane_inds]
    lefty = nonzeroy[left_lane_inds] 
    rightx = nonzerox[right_lane_inds]
    righty = nonzeroy[right_lane_inds]
    
    left_fit = None
    right_fit = None
    
    # ä½¿ç”¨é«˜æ–¯æ¬Šé‡é€²è¡Œå¤šé …å¼æ“¬åˆ
    # Fit a second order polynomial to the left and right lane points with Gaussian weighting
    if len(leftx) > 0:
        # è¨ˆç®—å·¦è»Šé“ç·šé»çš„å¹³å‡ x ä½ç½®ä½œç‚ºä¸­å¿ƒ
        left_mean_x = np.mean(leftx)
        # è¨­å®šæ¨™æº–å·®
        sigma = 30
        # è¨ˆç®—é«˜æ–¯æ¬Šé‡
        left_weights = np.exp(-((leftx - left_mean_x)**2) / (2 * sigma**2))
        try:
            left_fit = np.polyfit(lefty, leftx, 2, w=left_weights)
        except TypeError:
            left_fit = None

    if len(rightx) > 0:
        # è¨ˆç®—å³è»Šé“ç·šé»çš„å¹³å‡ x ä½ç½®ä½œç‚ºä¸­å¿ƒ
        right_mean_x = np.mean(rightx)
        # è¨­å®šæ¨™æº–å·®
        sigma = 30
        # è¨ˆç®—é«˜æ–¯æ¬Šé‡
        right_weights = np.exp(-((rightx - right_mean_x)**2) / (2 * sigma**2))
        try:
            right_fit = np.polyfit(righty, rightx, 2, w=right_weights)
        except TypeError:
            right_fit = None

    return left_fit, right_fit

def draw_lane_area(image, left_fit, right_fit):
    lane_image = np.zeros_like(image)
    if left_fit is None or right_fit is None:
        return lane_image

    ploty = np.linspace(0, image.shape[0]-1, image.shape[0])
    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]
    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]

    # å°‡æ“¬åˆçš„å¤šé …å¼é»è½‰æ›ç‚ºç¹ªåœ–ç”¨çš„å¤šé‚Šå½¢
    left_line_pts = np.array([np.transpose(np.vstack([left_fitx, ploty]))])
    right_line_pts = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])
    pts = np.hstack((left_line_pts, right_line_pts))

    cv2.fillPoly(lane_image, np.int32(pts), (0, 255, 0))
    cv2.polylines(lane_image, np.int32([left_line_pts]), False, (255, 0, 255), 6)
    cv2.polylines(lane_image, np.int32([right_line_pts]), False, (255, 0, 255), 6)
    return lane_image

def estimate_turn(left_fit, right_fit):
    if left_fit is None or right_fit is None:
        return "Detecting..."
    
    y_eval = 472
    left_x = left_fit[0]*y_eval**2 + left_fit[1]*y_eval + left_fit[2]
    right_x = right_fit[0]*y_eval**2 + right_fit[1]*y_eval + right_fit[2]

    delta = right_x - left_x - 300 # å‡è¨­çš„å¹³å‡è»Šé“å¯¬åº¦ç‚º300åƒç´ 
    if abs(delta) < 50:
        return "Straight"
    elif delta < 0:
        return "Turning Right"
    else:
        return "Turning Left"

# ==== Main Loop ====
frames_dir = "dataset/run_1756133797/frames"
frame_files = sorted(
    [f for f in os.listdir(frames_dir) if f.endswith(".jpg") or f.endswith(".png")]
)

if not frame_files:
    raise RuntimeError(f"No frames found in {frames_dir}")

# è®€ç¬¬ä¸€å¼µç¢ºå®šå¤§å°
first_frame = cv2.imread(os.path.join(frames_dir, frame_files[0]))
height, width = first_frame.shape[:2]
crop_height = int(height * (1 - CROP_BOTTOM_PERCENTAGE))

# è¨­å®šè¼¸å‡ºå½±ç‰‡
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter("output_bird_eye_view.mp4", fourcc, 20.0, (width, crop_height))

# é‡æ–°è¨ˆç®—é€è¦–è®Šæ›çŸ©é™£ï¼Œä½¿ç”¨è£åˆ‡å¾Œçš„é«˜åº¦
M, Minv = get_perspective_transforms(first_frame[:crop_height, :])

for fname in frame_files:
    frame = cv2.imread(os.path.join(frames_dir, fname))
    if frame is None:
        continue
    
    # æ ¹æ“š CROP_BOTTOM_PERCENTAGE è£åˆ‡ç•«é¢
    frame = frame[:crop_height, :]

    # --- è»Šé“ç·šåµæ¸¬æµç¨‹ ---
    # æ‡‰ç”¨å¤šå±¤æ¬¡åµæ¸¬ç­–ç•¥
    combined_mask = preprocess_frame(frame)
    
    # æ‡‰ç”¨é³¥ç°åœ–è½‰æ›åˆ°å½©è‰²åŸå§‹å½±åƒå’ŒäºŒå€¼åŒ–å½±åƒ
    bird_eye_color = cv2.warpPerspective(frame, M, (width, crop_height))
    bird_eye_edges = cv2.warpPerspective(combined_mask, M, (width, crop_height))

    # ä½¿ç”¨æ»‘å‹•è¦–çª—åœ¨é³¥ç°åœ–ä¸Šå°‹æ‰¾è»Šé“ç·šä¸¦æ“¬åˆå¤šé …å¼
    left_fit_poly, right_fit_poly = find_lane_pixels_and_fit_poly(bird_eye_edges)

    # ğŸ“‰ 3. è³‡æ–™å¹³æ»‘èˆ‡å»é›œè¨Šè™•ç†
    # âœ… æ™‚é–“å¹³æ»‘ï¼šä½¿ç”¨éå¾€å¸§è³‡æ–™
    # å°‡ç•¶å‰åµæ¸¬çµæœï¼ˆå¤šé …å¼ä¿‚æ•¸ï¼‰åŠ å…¥æ­·å²éšŠåˆ—
    if left_fit_poly is not None:
        left_history.append(left_fit_poly)
    if right_fit_poly is not None:
        right_history.append(right_fit_poly)

    # é€éæ­·å²è³‡æ–™è¨ˆç®—å¹³å‡å¤šé …å¼ä¿‚æ•¸
    avg_left_fit = np.average(list(left_history), axis=0) if left_history else None
    avg_right_fit = np.average(list(right_history), axis=0) if right_history else None

    # å°‡äºŒå€¼åŒ–é³¥ç°åœ–è½‰æ›ç‚ºä¸‰é€šé“ï¼Œä»¥ä¾¿åœ¨å…¶ä¸Šç¹ªè£½å½©è‰²è»Šé“ç·š
    bird_eye_edges_3ch = cv2.cvtColor(bird_eye_edges, cv2.COLOR_GRAY2BGR)

    # åœ¨å½©è‰²çš„é³¥ç°åœ–ä¸Šç¹ªè£½è»Šé“ç·šå’Œå¡«å……å€åŸŸ
    overlay = draw_lane_area(bird_eye_edges_3ch, avg_left_fit, avg_right_fit)
    output = cv2.addWeighted(bird_eye_edges_3ch, 1, overlay, 1, 1)

    # ä¼°è¨ˆè½‰å‘ä¸¦åœ¨é³¥ç°åœ–ä¸Šé¡¯ç¤º
    direction = estimate_turn(avg_left_fit, avg_right_fit)
    cv2.putText(output, direction, (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 4)

    out.write(output)
    cv2.namedWindow("ADAS Lane Detection - Bird's Eye View", cv2.WINDOW_NORMAL)
    cv2.resizeWindow("ADAS Lane Detection - Bird's Eye View", 960, 540)
    cv2.imshow("ADAS Lane Detection - Bird's Eye View", output)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

out.release()
cv2.destroyAllWindows()
