import cv2
import numpy as np
import os
from collections import deque

# åƒæ•¸è¨­å®š
# Parameter Configuration
left_history = deque(maxlen=10)
right_history = deque(maxlen=10)

# åƒæ•¸åŒ– Bird's Eye View çš„ä¾†æºé»ï¼Œæ–¹ä¾¿æ‰‹å‹•èª¿æ ¡
# These points are relative to the image dimensions (width, height).
# These are the corners of the trapezoid ROI in the original image.
BEV_SRC_POINTS_REL = np.float32([
    [0.25, 0.95],
    [0.75, 0.95],
    [0.6, 0.55],
    [0.4, 0.55]
])

# æ–°å¢åƒæ•¸ï¼šè£åˆ‡æ‰ç•«é¢çš„åº•éƒ¨ç™¾åˆ†æ¯”
# New parameter: Percentage of the bottom of the frame to crop
CROP_BOTTOM_PERCENTAGE = 0.3

# ğŸ” 1. å¤šå±¤æ¬¡çš„è»Šé“ç·šåµæ¸¬ç­–ç•¥
def preprocess_frame(frame):
    """
    çµåˆé¡è‰²èˆ‡æ¢¯åº¦äºŒå€¼åŒ–ï¼Œå¢å¼·åœ¨ä¸åŒå…‰ç·šæ¢ä»¶ä¸‹çš„ç©©å¥æ€§ã€‚
    Returns a combined binary image.
    """
    # âœ… é¡è‰²èˆ‡æ¢¯åº¦äºŒå€¼åŒ–çµåˆ
    # HLS è‰²å½©ç©ºé–“ç”¨æ–¼åµæ¸¬ç™½è‰²èˆ‡é»ƒè‰²ç·šæ¢ï¼Œå°å…‰ç·šè®ŠåŒ–æ›´ä¸æ•æ„Ÿ
    hls = cv2.cvtColor(frame, cv2.COLOR_BGR2HLS)
    white_mask = cv2.inRange(hls, np.array([0, 200, 0]), np.array([255, 255, 255]))
    yellow_mask = cv2.inRange(hls, np.array([15, 30, 115]), np.array([35, 204, 255]))
    color_mask = cv2.bitwise_or(white_mask, yellow_mask)

    # Sobel æ¢¯åº¦åµæ¸¬ï¼Œç”¨æ–¼æ‰¾å‡ºæ‰€æœ‰é«˜å°æ¯”åº¦çš„é‚Šç·£
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)
    abs_sobelx = np.absolute(sobelx)
    sobel_mask = cv2.inRange(np.uint8(255 * abs_sobelx / np.max(abs_sobelx)), 50, 255)

    # çµåˆå…©ç¨®é®ç½©
    combined_mask = cv2.bitwise_or(color_mask, sobel_mask)
    return combined_mask

# âœ… é³¥ç°è¦–è§’è½‰æ›ï¼ˆBirdâ€™s Eye Viewï¼‰
def get_perspective_transforms(frame):
    """
    å°‡ç•«é¢è½‰æ›ç‚ºä¿¯è¦–è¦–è§’ï¼Œå°‡æ›²ç·šè½‰ç‚ºæ¥è¿‘ç›´ç·šï¼Œä¾¿æ–¼å¾ŒçºŒè»Šé“ç·šæª¢æ¸¬èˆ‡æ“¬åˆã€‚
    å–å¾— Birdâ€™s Eye View (é€è¦–è½‰æ›) çš„è½‰æ›çŸ©é™£ã€‚
    è¼¸å…¥: BGR æˆ–ç°éš frame
    è¼¸å‡º: æ­£å‘å’Œåå‘çš„è½‰æ›çŸ©é™£ M å’Œ Minv
    """
    height, width = frame.shape[:2]

    # Use the global parameter to define the source points
    src = np.float32([
        [width * BEV_SRC_POINTS_REL[0, 0], height * BEV_SRC_POINTS_REL[0, 1]],
        [width * BEV_SRC_POINTS_REL[1, 0], height * BEV_SRC_POINTS_REL[1, 1]],
        [width * BEV_SRC_POINTS_REL[2, 0], height * BEV_SRC_POINTS_REL[2, 1]],
        [width * BEV_SRC_POINTS_REL[3, 0], height * BEV_SRC_POINTS_REL[3, 1]]
    ])
    
    # è¨ˆç®—ç›®æ¨™é»
    # Define the new dst points as a perfect rectangle,
    # mapping the src trapezoid to the entire output frame.
    dst = np.float32([
        [0, height],        # bottom-left
        [width, height],    # bottom-right
        [width, 0],         # top-right
        [0, 0]              # top-left
    ])

    M = cv2.getPerspectiveTransform(src, dst)
    Minv = cv2.getPerspectiveTransform(dst, src)
    return M, Minv

def make_coordinates(image, line_params):
    slope, intercept = line_params
    y1 = image.shape[0]
    y2 = int(y1 * 0.6)
    if slope == 0: slope = 0.1
    x1 = int((y1 - intercept) / slope)
    x2 = int((y2 - intercept) / slope)
    return np.array([x1, y1, x2, y2])

# ğŸ§  2. æ™ºèƒ½åŒ–è»Šé“ç·šæ“¬åˆæµç¨‹
# è¨»ï¼šæ­¤è™•æ¡ç”¨ Hough è®Šæ›é€²è¡Œè»Šé“ç·šæ“¬åˆï¼Œä½†ä»¥ä¸‹è¨»è§£è§£é‡‹äº†æ›´é€²éšçš„æ™ºèƒ½åŒ–æ“¬åˆç†å¿µã€‚
def average_slope_intercept(image, lines):
    left_fit, right_fit = [], []
    img_center = image.shape[1] // 2
    if lines is None:
        return None, None
    for line in lines:
        x1, y1, x2, y2 = line.reshape(4)
        if x2 - x1 == 0: continue
        slope = (y2 - y1) / (x2 - x1)
        intercept = y1 - slope * x1
        if slope < -0.3 and x1 < img_center and x2 < img_center:
            left_fit.append((slope, intercept))
        elif slope > 0.3 and x1 > img_center and x2 > img_center:
            right_fit.append((slope, intercept))
    
    left_line = make_coordinates(image, np.average(left_fit, axis=0)) if left_fit else None
    right_line = make_coordinates(image, np.average(right_fit, axis=0)) if right_fit else None
    
    # âœ… å‹•æ…‹ä¿®æ­£éŒ¯èª¤åµæ¸¬ï¼ˆå·¦å³ç·šè·é›¢æª¢æŸ¥ï¼‰
    # å¦‚æœå·¦å³ç·šé–“è·å¤ªå¤§æˆ–å¤ªå°ï¼Œæœƒå˜—è©¦ä¿®æ­£å·¦ç·šçš„ä½ç½®ï¼Œé¿å…è»Šé“ç·šè¿½è¹¤éŒ¯èª¤ã€‚
    if left_line is not None and right_line is not None:
        lane_width = (right_line[0] - left_line[0])
        avg_lane_width = 300 # å‡è¨­çš„å¹³å‡è»Šé“å¯¬åº¦
        if abs(lane_width - avg_lane_width) > 100:
            # åµæ¸¬åˆ°ç•°å¸¸å¯¬åº¦ï¼Œå˜—è©¦ä½¿ç”¨æ­·å²è³‡æ–™é€²è¡Œä¿®æ­£ï¼ˆæ­¤è™•åƒ…ç‚ºé‚è¼¯ç¤ºç¯„ï¼‰
            pass # é€™è£¡å¯ä»¥åŠ å…¥æ›´è¤‡é›œçš„ä¿®æ­£é‚è¼¯

    return left_line, right_line

def draw_lane_area(image, left_line, right_line):
    lane_image = np.zeros_like(image)
    if left_line is not None:
        cv2.line(lane_image, tuple(left_line[:2]), tuple(left_line[2:]), (255, 0, 255), 6)
    if right_line is not None:
        cv2.line(lane_image, tuple(right_line[:2]), tuple(right_line[2:]), (255, 0, 255), 6)
    if left_line is not None and right_line is not None:
        if left_line[0] < right_line[0] and left_line[2] < right_line[2]:
            points = np.array([[
                tuple(left_line[:2]),
                tuple(left_line[2:]),
                tuple(right_line[2:]),
                tuple(right_line[:2])
            ]], dtype=np.int32)
            cv2.fillPoly(lane_image, points, (0, 255, 0))
    return lane_image

def estimate_turn(left, right):
    if left is None or right is None:
        return "Detecting..."
    mid_bottom = (left[0] + right[0]) // 2
    mid_top = (left[2] + right[2]) // 2
    delta = mid_top - mid_bottom
    if abs(delta) < 30:
        return "Straight"
    elif delta < 0:
        return "Turning Left"
    else:
        return "Turning Right"


# ==== æ”¹é€™è£¡ï¼šè®€å– run_* çš„ frames ====
frames_dir = "dataset/run_1756133797/frames"    # ä¿®æ”¹æˆä½ çš„ run_* è³‡æ–™å¤¾
frame_files = sorted(
    [f for f in os.listdir(frames_dir) if f.endswith(".jpg") or f.endswith(".png")]
)

if not frame_files:
    raise RuntimeError(f"No frames found in {frames_dir}")

# è®€ç¬¬ä¸€å¼µç¢ºå®šå¤§å°
first_frame = cv2.imread(os.path.join(frames_dir, frame_files[0]))
height, width = first_frame.shape[:2]
crop_height = int(height * (1 - CROP_BOTTOM_PERCENTAGE))

# è¨­å®šè¼¸å‡ºå½±ç‰‡
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter("output_bird_eye_view.mp4", fourcc, 20.0, (width, crop_height))

# é‡æ–°è¨ˆç®—é€è¦–è®Šæ›çŸ©é™£ï¼Œä½¿ç”¨è£åˆ‡å¾Œçš„é«˜åº¦
M, Minv = get_perspective_transforms(first_frame[:crop_height, :])

for fname in frame_files:
    frame = cv2.imread(os.path.join(frames_dir, fname))
    if frame is None:
        continue
    
    # æ ¹æ“š CROP_BOTTOM_PERCENTAGE è£åˆ‡ç•«é¢
    # Crop the frame based on the CROP_BOTTOM_PERCENTAGE
    frame = frame[:crop_height, :]

    # --- è»Šé“ç·šåµæ¸¬æµç¨‹ ---
    # æ‡‰ç”¨å¤šå±¤æ¬¡åµæ¸¬ç­–ç•¥
    combined_mask = preprocess_frame(frame)
    
    # æ‡‰ç”¨é³¥ç°åœ–è½‰æ›åˆ°å½©è‰²åŸå§‹å½±åƒå’ŒäºŒå€¼åŒ–å½±åƒ
    bird_eye_color = cv2.warpPerspective(frame, M, (width, crop_height))
    bird_eye_edges = cv2.warpPerspective(combined_mask, M, (width, crop_height))

    # åœ¨é³¥ç°åœ–ä¸Šå°‹æ‰¾è»Šé“ç·š
    lines = cv2.HoughLinesP(bird_eye_edges, 1, np.pi / 180, 60,
                            minLineLength=40, maxLineGap=150)

    # æ‰¾åˆ°å¹³å‡è»Šé“ç·šï¼Œé€™è£¡çš„åº§æ¨™å·²ç¶“æ˜¯åœ¨é³¥ç°åœ–ä¸Š
    left_line_be, right_line_be = average_slope_intercept(bird_eye_edges, lines)

    # ğŸ“‰ 3. è³‡æ–™å¹³æ»‘èˆ‡å»é›œè¨Šè™•ç†
    # âœ… æ™‚é–“å¹³æ»‘ï¼šä½¿ç”¨éå¾€å¸§è³‡æ–™
    # å°‡ç•¶å‰åµæ¸¬çµæœåŠ å…¥æ­·å²éšŠåˆ—
    if left_line_be is not None:
        left_history.append(left_line_be)
    if right_line_be is not None:
        right_history.append(right_line_be)

    # é€éæ­·å²è³‡æ–™è¨ˆç®—å¹³å‡å€¼ï¼Œä½¿è»Šé“ç·šåœ¨å½±ç‰‡ä¸­ä¸æœƒè·³å‹•æˆ–é–ƒçˆ
    avg_left_line = np.average(list(left_history), axis=0).astype(int) if left_history else None
    avg_right_line = np.average(list(right_history), axis=0).astype(int) if right_history else None

    # å°‡äºŒå€¼åŒ–é³¥ç°åœ–è½‰æ›ç‚ºä¸‰é€šé“ï¼Œä»¥ä¾¿åœ¨å…¶ä¸Šç¹ªè£½å½©è‰²è»Šé“ç·š
    bird_eye_edges_3ch = cv2.cvtColor(bird_eye_edges, cv2.COLOR_GRAY2BGR)

    # åœ¨å½©è‰²çš„é³¥ç°åœ–ä¸Šç¹ªè£½è»Šé“ç·šå’Œå¡«å……å€åŸŸ
    overlay = draw_lane_area(bird_eye_edges_3ch, avg_left_line, avg_right_line)
    output = cv2.addWeighted(bird_eye_edges_3ch, 1, overlay, 1, 1)

    # ä¼°è¨ˆè½‰å‘ä¸¦åœ¨é³¥ç°åœ–ä¸Šé¡¯ç¤º
    direction = estimate_turn(avg_left_line, avg_right_line)
    cv2.putText(output, direction, (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 4)

    out.write(output)
    cv2.namedWindow("ADAS Lane Detection - Bird's Eye View", cv2.WINDOW_NORMAL)
    cv2.resizeWindow("ADAS Lane Detection - Bird's Eye View", 960, 540)
    cv2.imshow("ADAS Lane Detection - Bird's Eye View", output)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

out.release()
cv2.destroyAllWindows()
